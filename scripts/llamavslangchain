<!doctype html><html lang="en"><head><title data-rh="true">Comparison of LLamaIndex and LangChain | by Zahid Ali | Oct, 2023 | Medium</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2023-10-30T13:37:59.299Z"/><meta data-rh="true" name="title" content="Comparison of LLamaIndex and LangChain | by Zahid Ali | Oct, 2023 | Medium"/><meta data-rh="true" property="og:title" content="Comparison of LLamaIndex and LangChain"/><meta data-rh="true" property="al:android:url" content="medium://p/4900989752ac"/><meta data-rh="true" property="al:ios:url" content="medium://p/4900989752ac"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="LLamaIndex is the essential bridge between your data and powerful language models (LLMs), streamlining data tasks with user-friendly features. It allows you to create organized data indexes, leverage…"/><meta data-rh="true" property="og:description" content="In the world of data and language tools, we have two strong contenders: LlamaIndex and LangChain. LlamaIndex boasts impressive speed and…"/><meta data-rh="true" property="og:url" content="https://medium.com/@zahidali133/comparison-of-llamaindex-and-langchain-4900989752ac"/><meta data-rh="true" property="al:web:url" content="https://medium.com/@zahidali133/comparison-of-llamaindex-and-langchain-4900989752ac"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Qk7PU6HYRVomP0ZE"/><meta data-rh="true" property="og:image:alt" content="https://python.langchain.com/docs/modules/model_io/"/><meta data-rh="true" property="article:author" content="https://medium.com/@zahidali133"/><meta data-rh="true" name="author" content="Zahid Ali"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Comparison of LLamaIndex and LangChain"/><meta data-rh="true" name="twitter:site" content="@Medium"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/4900989752ac"/><meta data-rh="true" property="twitter:description" content="In the world of data and language tools, we have two strong contenders: LlamaIndex and LangChain. LlamaIndex boasts impressive speed and…"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Qk7PU6HYRVomP0ZE"/><meta data-rh="true" name="twitter:image:alt" content="https://python.langchain.com/docs/modules/model_io/"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:creator" content="@zahidali133"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="14 min read"/><meta data-rh="true" name="twitter:tile:template:testing" content="2"/><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Qk7PU6HYRVomP0ZE"/><meta data-rh="true" name="twitter:tile:image:alt" content="https://python.langchain.com/docs/modules/model_io/"/><meta data-rh="true" name="twitter:tile:info1:icon" content="Person"/><meta data-rh="true" name="twitter:tile:info1:text" content="Zahid Ali"/><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"/><meta data-rh="true" name="twitter:tile:info2:text" content="Oct 30, 2023"/><meta data-rh="true" name="twitter:cta" content="Read on Medium"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@zahidali133"/><link data-rh="true" rel="canonical" href="https://medium.com/@zahidali133/comparison-of-llamaindex-and-langchain-4900989752ac"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/4900989752ac"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fda:true\u002Fresize:fit:1200\u002F0*Qk7PU6HYRVomP0ZE"],"url":"https:\u002F\u002Fmedium.com\u002F@zahidali133\u002Fcomparison-of-llamaindex-and-langchain-4900989752ac","dateCreated":"2023-10-30T11:10:52.236Z","datePublished":"2023-10-30T11:10:52.236Z","dateModified":"2023-10-30T13:38:04.165Z","headline":"Comparison of LLamaIndex and LangChain - Zahid Ali - Medium","name":"Comparison of LLamaIndex and LangChain - Zahid Ali - Medium","description":"LLamaIndex is the essential bridge between your data and powerful language models (LLMs), streamlining data tasks with user-friendly features. It allows you to create organized data indexes, leverage…","identifier":"4900989752ac","author":{"@type":"Person","name":"Zahid Ali","url":"https:\u002F\u002Fmedium.com\u002F@zahidali133"},"creator":["Zahid Ali"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fmedium.com\u002F","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:616\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002F@zahidali133\u002Fcomparison-of-llamaindex-and-langchain-4900989752ac"}</script><style type="text/css" data-fela-rehydration="498" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="498" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.dx{margin:0 24px}.eb{background:rgba(255, 255, 255, 1)}.ec{box-sizing:border-box}.ed{border:1px solid #F2F2F2}.ee{box-shadow:0 1px 4px #F2F2F2}.ef{max-height:100vh}.eg{overflow-y:auto}.eh{position:absolute}.ei{left:0}.ej{top:calc(100vh + 100px)}.ek{bottom:calc(100vh + 100px)}.el{width:10px}.em{pointer-events:none}.eo{word-break:break-word}.ep{word-wrap:break-word}.eq:after{display:block}.er:after{content:""}.es:after{clear:both}.et{line-height:1.23}.eu{letter-spacing:0}.ev{font-style:normal}.ew{font-weight:700}.fw{@media all and (max-width: 551.98px):8px}.fx{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.fy{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.fz{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.ga{@media all and (min-width: 1080px):16px}.gg{align-items:baseline}.gh{width:48px}.gi{height:48px}.gj{border:2px solid rgba(255, 255, 255, 1)}.gk{z-index:0}.gl{box-shadow:none}.gm{border:1px solid rgba(0, 0, 0, 0.05)}.go{position:relative}.gp{margin-bottom:2px}.gq{flex-wrap:nowrap}.gr{font-size:16px}.gs{line-height:24px}.gu{margin:0 8px}.gv{display:inline}.gw{color:#6B6B6B}.gx{color:#1A8917}.gy{fill:#1A8917}.gz:disabled{opacity:0.3}.hc{flex:0 0 auto}.hf{flex-wrap:wrap}.hg{padding-left:8px}.hh{padding-right:8px}.ii> *{flex-shrink:0}.ij{overflow-x:scroll}.ik::-webkit-scrollbar{display:none}.il{scrollbar-width:none}.im{-ms-overflow-style:none}.ip{width:74px}.iq{flex-direction:row}.ir{margin-right:4px}.iu{-webkit-user-select:none}.iv{border:0}.iw{cursor:progress}.ix{fill:rgba(117, 117, 117, 1)}.ja{opacity:0.25}.jb{outline:0}.jc{user-select:none}.jd> svg{pointer-events:none}.jm{font-size:13px}.jn{margin-left:4px}.jo{margin-top:0px}.jp{opacity:1}.jq{padding:4px 0}.jr{fill:#6B6B6B}.ju{width:16px}.jv{display:inline-flex}.kb{max-width:100%}.kc{padding:8px 2px}.kd svg{color:#6B6B6B}.ku{line-height:1.12}.kv{letter-spacing:-0.022em}.kw{font-weight:600}.lr{margin-bottom:-0.28em}.ls{line-height:1.58}.lt{letter-spacing:-0.004em}.lu{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.mp{margin-bottom:-0.46em}.mv{list-style-type:disc}.mw{margin-left:30px}.mx{padding-left:0px}.nd{margin-top:32px}.ne{margin-bottom:14px}.nf{padding-top:24px}.ng{padding-bottom:10px}.nh{background-color:#000000}.ni{height:3px}.nj{width:3px}.nk{margin-right:20px}.nq{margin-left:auto}.nr{margin-right:auto}.ns{max-width:1600px}.ny{clear:both}.oa{cursor:zoom-in}.ob{z-index:auto}.od{height:auto}.oe{box-shadow:inset 3px 0 0 0 #242424}.of{padding-left:23px}.og{margin-left:-20px}.oh{font-style:italic}.oi{line-height:1.18}.oy{margin-bottom:-0.31em}.oz{text-decoration:underline}.pa{margin-bottom:26px}.pb{margin-top:6px}.pc{margin-top:8px}.pd{margin-right:8px}.pe{padding:8px 16px}.pf{border-radius:100px}.pg{transition:background 300ms ease}.pi{white-space:nowrap}.pj{border-top:none}.pp{height:52px}.pq{max-height:52px}.pr{box-sizing:content-box}.ps{position:static}.pt{z-index:1}.pv{max-width:155px}.qg{align-items:flex-end}.qh{width:76px}.qi{height:76px}.qj{border:2px solid #F9F9F9}.qk{height:72px}.ql{width:72px}.qm{color:#FFFFFF}.qn{fill:#FFFFFF}.qo{background:#1A8917}.qp{border-color:#1A8917}.qt:disabled{cursor:inherit !important}.qu:disabled:hover{background:#1A8917}.qv:disabled:hover{border-color:#1A8917}.qw{border-radius:99em}.qx{width:auto}.qy{border-width:1px}.qz{border-style:solid}.ra{text-decoration:none}.rb{text-align:center}.rc{margin-left:8px}.rd{stroke:#F2F2F2}.re{height:36px}.rf{width:36px}.rg{color:#F2F2F2}.rh{fill:#F2F2F2}.ri{background:#F2F2F2}.rj{border-color:#F2F2F2}.rp{font-weight:500}.rq{font-size:24px}.rr{line-height:30px}.rs{letter-spacing:-0.016em}.rt{margin-top:16px}.ru{height:0px}.rv{border-bottom:solid 1px #E5E5E5}.sb{margin-top:72px}.sc{padding:24px 0}.sd{margin-bottom:0px}.se{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.gn:hover{background-color:rgba(0, 0, 0, 0.1)}.gt:hover{text-decoration:underline}.ha:hover:not(:disabled){color:#156D12}.hb:hover:not(:disabled){fill:#156D12}.iz:hover{fill:rgba(117, 117, 117, 1)}.js:hover{fill:#000000}.jt:hover p{color:#000000}.ke:hover svg{color:#000000}.ph:hover{background-color:#F2F2F2}.qq:hover{background:#156D12}.qr:hover{border-color:#156D12}.qs:hover{cursor:pointer}.rk:hover{background:#F2F2F2}.rl:hover{border-color:#F2F2F2}.rm:hover{cursor:wait}.rn:hover{color:#F2F2F2}.ro:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.iy:focus{fill:rgba(117, 117, 117, 1)}.kf:focus svg{color:#000000}.oc:focus{transform:scale(1.01)}.je:active{border-style:none}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.dw{margin-bottom:68px}.ea{max-width:680px}.fr{font-size:42px}.fs{margin-top:1.19em}.ft{margin-bottom:32px}.fu{line-height:52px}.fv{letter-spacing:-0.011em}.gf{align-items:center}.hu{border-top:solid 1px #F2F2F2}.hv{border-bottom:solid 1px #F2F2F2}.hw{margin:32px 0 0}.hx{padding:3px 8px}.ig> *{margin-right:24px}.ih> :last-child{margin-right:0}.io{display:flex}.jl{margin-top:0px}.ka{margin:0}.ln{font-size:24px}.lo{margin-top:1.95em}.lp{line-height:30px}.lq{letter-spacing:-0.016em}.ml{font-size:20px}.mm{margin-top:0.94em}.mn{line-height:32px}.mo{letter-spacing:-0.003em}.mu{margin-top:2.14em}.nc{margin-top:1.14em}.np{margin-top:1.25em}.nx{margin-top:56px}.ov{margin-top:1.72em}.ow{line-height:24px}.ox{letter-spacing:0}.po{margin-bottom:88px}.qa{display:inline-block}.qf{padding-top:72px}.sa{margin-top:40px}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.jk{margin-top:0px}.pz{display:inline-block}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.jj{margin-top:0px}.py{display:inline-block}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.jh{margin-top:0px}.ji{margin-right:0px}.px{display:inline-block}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.ds{margin-bottom:4px}.ex{font-size:32px}.ey{margin-top:1.01em}.ez{margin-bottom:24px}.fa{line-height:38px}.fb{letter-spacing:-0.014em}.gb{align-items:flex-start}.hd{flex-direction:column}.hi{margin:24px -24px 0}.hj{padding:0}.hy> *{margin-right:8px}.hz> :last-child{margin-right:24px}.is{margin-left:0px}.jf{margin-top:0px}.jg{margin-right:0px}.jw{margin:0}.kg{border:1px solid #F2F2F2}.kh{border-radius:99em}.ki{padding:0px 16px 0px 12px}.kj{height:38px}.kk{align-items:center}.km svg{margin-right:8px}.kx{font-size:20px}.ky{margin-top:1.2em}.kz{line-height:24px}.la{letter-spacing:0}.lv{font-size:18px}.lw{margin-top:0.67em}.lx{line-height:28px}.ly{letter-spacing:-0.003em}.mq{margin-top:1.56em}.my{margin-top:1.34em}.nl{margin-top:0.93em}.nt{margin-top:40px}.oj{font-size:16px}.ok{margin-top:1.23em}.ol{line-height:20px}.pk{margin-bottom:80px}.pw{display:inline-block}.qb{padding-top:48px}.rw{margin-top:32px}.kl:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.dv{margin-bottom:68px}.dz{max-width:680px}.fm{font-size:42px}.fn{margin-top:1.19em}.fo{margin-bottom:32px}.fp{line-height:52px}.fq{letter-spacing:-0.011em}.ge{align-items:center}.hq{border-top:solid 1px #F2F2F2}.hr{border-bottom:solid 1px #F2F2F2}.hs{margin:32px 0 0}.ht{padding:3px 8px}.ie> *{margin-right:24px}.if> :last-child{margin-right:0}.in{display:flex}.jz{margin:0}.lj{font-size:24px}.lk{margin-top:1.95em}.ll{line-height:30px}.lm{letter-spacing:-0.016em}.mh{font-size:20px}.mi{margin-top:0.94em}.mj{line-height:32px}.mk{letter-spacing:-0.003em}.mt{margin-top:2.14em}.nb{margin-top:1.14em}.no{margin-top:1.25em}.nw{margin-top:56px}.os{margin-top:1.72em}.ot{line-height:24px}.ou{letter-spacing:0}.pn{margin-bottom:88px}.qe{padding-top:72px}.rz{margin-top:40px}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.du{margin-bottom:68px}.dy{max-width:680px}.fh{font-size:42px}.fi{margin-top:1.19em}.fj{margin-bottom:32px}.fk{line-height:52px}.fl{letter-spacing:-0.011em}.gd{align-items:center}.hm{border-top:solid 1px #F2F2F2}.hn{border-bottom:solid 1px #F2F2F2}.ho{margin:32px 0 0}.hp{padding:3px 8px}.ic> *{margin-right:24px}.id> :last-child{margin-right:0}.jy{margin:0}.lf{font-size:24px}.lg{margin-top:1.95em}.lh{line-height:30px}.li{letter-spacing:-0.016em}.md{font-size:20px}.me{margin-top:0.94em}.mf{line-height:32px}.mg{letter-spacing:-0.003em}.ms{margin-top:2.14em}.na{margin-top:1.14em}.nn{margin-top:1.25em}.nv{margin-top:56px}.op{margin-top:1.72em}.oq{line-height:24px}.or{letter-spacing:0}.pm{margin-bottom:88px}.qd{padding-top:72px}.ry{margin-top:40px}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dt{margin-bottom:4px}.fc{font-size:32px}.fd{margin-top:1.01em}.fe{margin-bottom:24px}.ff{line-height:38px}.fg{letter-spacing:-0.014em}.gc{align-items:flex-start}.he{flex-direction:column}.hk{margin:24px 0 0}.hl{padding:0}.ia> *{margin-right:8px}.ib> :last-child{margin-right:8px}.it{margin-left:0px}.jx{margin:0}.kn{border:1px solid #F2F2F2}.ko{border-radius:99em}.kp{padding:0px 16px 0px 12px}.kq{height:38px}.kr{align-items:center}.kt svg{margin-right:8px}.lb{font-size:20px}.lc{margin-top:1.2em}.ld{line-height:24px}.le{letter-spacing:0}.lz{font-size:18px}.ma{margin-top:0.67em}.mb{line-height:28px}.mc{letter-spacing:-0.003em}.mr{margin-top:1.56em}.mz{margin-top:1.34em}.nm{margin-top:0.93em}.nu{margin-top:40px}.om{font-size:16px}.on{margin-top:1.23em}.oo{line-height:20px}.pl{margin-bottom:80px}.qc{padding-top:48px}.rx{margin-top:32px}.ks:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="print">.pu{display:none}</style><style type="text/css" data-fela-rehydration="498" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nz{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" rel="noopener follow" href="/?source=---two_column_layout_nav----------------------------------"><svg viewBox="0 0 3940 610" class="au av"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search" value=""/></div></div></div><div class="bo bp bq br bs bt bu bv bw"></div><div class="bo bp bq br h bs k bt bu bv bw"></div><div class="bo bp bq br h bs k bt bu bv bw"></div><div class="bx bp by bz bw"></div></div></div><div class="l"><div class="ds dt du dv dw l"><div class="ab ca"><div class="ch bg dx dy dz ea"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="eh ei ej ek el em"></div><div class="eo ep eq er es"><div class="ab ca"><div class="ch bg dx dy dz ea"><div><h1 id="78c1" class="pw-post-title et eu ev be ew ex ey ez fa fb fc fd fe ff fg fh fi fj fk fl fm fn fo fp fq fr fs ft fu fv bj" data-testid="storyTitle">Comparison of LLamaIndex and LangChain</h1><div class="fw fx fy fz ga"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="gb gc gd ge gf ab"><div><div class="ab gg"><a rel="noopener follow" href="/@zahidali133?source=post_page-----4900989752ac--------------------------------"><div><div class="bl" aria-hidden="false"><div class="l gh gi bx gj gk"><div class="l go"><img alt="Zahid Ali" class="l ec bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/1*tJ2LDg0bvxvOhOqdpc-EJA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="gl bx l dc dd eh n gm gn"></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="gp ab q"><div class="ab q gq"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b gr gs bj"><a class="af ag ah ai aj ak al am an ao ap aq ar gt" data-testid="authorName" rel="noopener follow" href="/@zahidali133?source=post_page-----4900989752ac--------------------------------">Zahid Ali</a></p></div></div></div><span class="gu gv" aria-hidden="true"><span class="be b bf z gw">·</span></span><p class="be b gr gs gw"><span><a class="gx gy ah ai aj ak al am an ao ap aq ar gz ha hb" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8ecd3d43dbb4&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40zahidali133%2Fcomparison-of-llamaindex-and-langchain-4900989752ac&amp;user=Zahid+Ali&amp;userId=8ecd3d43dbb4&amp;source=post_page-8ecd3d43dbb4----4900989752ac---------------------post_header-----------">Follow</a></span></p></div></div></span></div></div><div class="l hc"><span class="be b bf z gw"><div class="ab cm hd he hf"><span class="be b bf z gw"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="hg hh l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z gw">·</span></span></div><span data-testid="storyPublishDate">Oct 30</span></div></span></div></span></div></div></div><div class="ab co hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx"><div class="h k w in io q"><div class="ip l"><div class="ab q iq"><div class="pw-multi-vote-icon go ir is it iu"><div class=""><div class="iv iw ix iy iz ja jb am jc jd je iu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM15.42 1.84l-1.18-.39-.34 2.5 1.52-2.1zM9.76 1.45l-1.19.4 1.53 2.1-.34-2.5zM20.25 11.84l-2.5-4.4a1.42 1.42 0 0 0-.93-.64.96.96 0 0 0-.75.18c-.25.19-.4.42-.45.7l.05.05 2.35 4.13c1.62 2.95 1.1 5.78-1.52 8.4l-.46.41c1-.13 1.93-.6 2.78-1.45 2.7-2.7 2.51-5.59 1.43-7.38zM12.07 9.01c-.13-.69.08-1.3.57-1.77l-2.06-2.07a1.12 1.12 0 0 0-1.56 0c-.15.15-.22.34-.27.53L12.07 9z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.74 8.3a1.13 1.13 0 0 0-.73-.5.67.67 0 0 0-.53.13c-.15.12-.59.46-.2 1.3l1.18 2.5a.45.45 0 0 1-.23.76.44.44 0 0 1-.48-.25L7.6 6.11a.82.82 0 1 0-1.15 1.15l3.64 3.64a.45.45 0 1 1-.63.63L5.83 7.9 4.8 6.86a.82.82 0 0 0-1.33.9c.04.1.1.18.18.26l1.02 1.03 3.65 3.64a.44.44 0 0 1-.15.73.44.44 0 0 1-.48-.1L4.05 9.68a.82.82 0 0 0-1.4.57.81.81 0 0 0 .24.58l1.53 1.54 2.3 2.28a.45.45 0 0 1-.64.63L3.8 13a.81.81 0 0 0-1.39.57c0 .22.09.43.24.58l4.4 4.4c2.8 2.8 5.5 4.12 8.68.94 2.27-2.28 2.71-4.6 1.34-7.1l-2.32-4.08z"></path></svg></div></div></div><div class="pw-multi-vote-count l jf jg jh ji jj jk jl"><p class="be b jm z gw"><span class="iw">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao iv jp jq ab q jr js jt" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="jo"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b jm z gw"><span class="pw-responses-count jn jo">1</span></p></button></div></div></div><div class="ab q hy hz ia ib ic id ie if ig ih ii ij ik il im"><div class="ju k j i d"></div><div class="h k"></div><div class="ec jv cm"><div class="l ae"><div class="ab ca"><div class="jw jx jy jz ka kb ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af jr ah ai aj ak al kc an ao ap gz kd ke jt kf kg kh ki kj s kk kl km kn ko kp kq u kr ks kt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z gw">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af jr ah ai aj ak al kc an ao ap gz kd ke jt kf kg kh ki kj s kk kl km kn ko kp kq u kr ks kt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z gw">Share</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="65c1" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj">General Overview</h1><h1 id="f09c" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">LLamaIndex</strong></h1><p id="d577" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj">LLamaIndex is the essential bridge between your data and powerful language models (LLMs), streamlining data tasks with user-friendly features. It allows you to create organized data indexes, leverage multiple LLMs with diverse strengths, augment your data for improved LLM performance, and easily query your data using natural language. If you’re looking to unlock the full potential of your LLMs for document-based tasks, LLamaIndex is the game-changing solution, making data-driven insights more accessible and efficient, ensuring your data works harder for you.</p><h1 id="ba37" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">Tools offered by LLamaIndex:</strong></h1><p id="282d" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj"><strong class="lu ew">Data Connectors: </strong>Data connectors are the unsung heroes of data integration, simplifying the complex task of bridging the gap between your data sources and your data repository. Without them, manual data extraction, transformation, and loading (ETL) would be a cumbersome and error-prone process. These connectors offer a seamless way to ingest data directly from its native source and format, eliminating the need for time-consuming data conversion. Furthermore, data connectors come with a host of advantages, such as automatically enhancing data quality, securing data through encryption, boosting data performance via caching, and reducing the maintenance efforts required for your data integration solution. If you’re seeking to streamline your data integration process, data connectors provide a flexible and scalable solution to maximize the potential of your data. So, remember to credit these essential tools for making efficient data integration a reality.</p><p id="fbdd" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Data Indexes: </strong>Think of an index like the super-speedy assistant for your data searches. It’s what makes LlamaIndex work seamlessly for question-answering and chat functions with your data. These indexes are built from your documents and make it possible for you to ask questions or have conversations with your data.</p><p id="0046" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Behind the scenes, these indexes are like puzzle pieces, representing parts of your original documents. They also have special tools to make data retrieval smoother and more efficient, kind of like having an automatic search feature. So, even though they might seem technical, indexes are the key to making your experience with LlamaIndex simple and user-friendly when working with your data.</p><p id="b1f5" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Engines: </strong>LLamaIndex Engines are the magic behind making data and large language models (LLMs) work together seamlessly. They provide a flexible framework to connect LLMs to various data sources, making it simple for them to access real-world information. At their core, these engines feature a clever search system that understands natural language queries, making data interaction a breeze. But that’s not all — they can also organize your data for faster access, add extra information to improve your LLM-powered applications, and help you choose the right LLM for the job. In a nutshell, LLamaIndex Engines are the key to creating a wide range of LLM-powered applications, serving as the bridge between data and LLMs to tackle real-world challenges.</p><p id="eae3" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Data Agents: </strong>Data Agents, the brainy LLM-powered knowledge workers within LlamaIndex, are the ultimate multitaskers when it comes to managing your data. They possess the unique ability to intelligently sift through unstructured, semi-structured, and structured data sources, as well as interact with external service APIs in an organized manner, all while handling both “read” and “write” operations. This versatility makes them indispensable for automating data-related tasks. Unlike query engines that are limited to “reading” data from static sources, Data Agents can dynamically ingest and modify data from various tools, making them highly adaptable to evolving data environments. Building a Data Agent involves defining a reasoning loop for decision-making and creating tool abstractions to provide a consistent interface for interacting with different tools. LlamaIndex supports two types of Data Agents: OpenAI Function agents, based on the OpenAI Function API, and ReAct agents, which can collaborate with any chat/text completion endpoint. In essence, Data Agents bring together the prowess of LLMs and the flexibility of tool abstractions to usher in a new era of automation and intelligence within your data workflows.</p><p id="8fa7" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Application Integrations: </strong>LLamaIndex is a powerful tool for building large language model (LLM)-powered applications. However, its true potential is unlocked through its extensive integrations with other tools and services.</p><p id="707a" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">These integrations make it easy to connect LLamaindex to a wide range of data sources, observability tools, and application frameworks. This allows you to build more powerful and versatile LLM-powered applications.</p><p id="aab9" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">For example, LLamaindex can be integrated with vector stores, such as Pinecone and Milvus, to enable efficient search and retrieval of similar documents. It can also be integrated with tracing tools, such as Graphsignal, to provide insights into the inner workings of LLM-powered applications.</p><p id="ea69" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">In addition, LLamaindex can be integrated with application frameworks, such as Langchain and Streamlit, to make it easier to build and deploy LLM-powered applications.</p><p id="ab2e" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Overall, the integrations available for LLamaindex make it a powerful and versatile tool for building a wide range of LLM-powered applications.</p><p id="0df4" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Here are some specific examples of LLamaindex integrations:</p><ul class=""><li id="e9eb" class="ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp mv mw mx bj"><strong class="lu ew">Data loaders:</strong> LLamaindex can be integrated with a variety of data loaders, such as Airbyte and Poe, to make it easy to ingest data from a variety of sources.</li><li id="32bf" class="ls lt ev lu b lv my lx ly lz mz mb mc md na mf mg mh nb mj mk ml nc mn mo mp mv mw mx bj"><strong class="lu ew">Agent tools:</strong> LLamaindex can be integrated with a variety of agent tools, such as ChatGPT plugins and OpenAI Function Calling, to extend the capabilities of Data Agents.</li><li id="e24b" class="ls lt ev lu b lv my lx ly lz mz mb mc md na mf mg mh nb mj mk ml nc mn mo mp mv mw mx bj"><strong class="lu ew">Observability/tracing/evaluation:</strong> LLamaindex can be integrated with a variety of observability/tracing/evaluation tools, such as Graphsignal, TruLens, and DeepEval, to provide insights into the performance of LLM-powered applications.</li><li id="fa12" class="ls lt ev lu b lv my lx ly lz mz mb mc md na mf mg mh nb mj mk ml nc mn mo mp mv mw mx bj"><strong class="lu ew">Structured outputs:</strong> LLamaindex can be integrated with a variety of structured output formats, such as CSV, JSON, and SQL, to make it easy to consume the results of LLM-powered applications.</li><li id="52d1" class="ls lt ev lu b lv my lx ly lz mz mb mc md na mf mg mh nb mj mk ml nc mn mo mp mv mw mx bj"><strong class="lu ew">Application frameworks:</strong> LLamaindex can be integrated with a variety of application frameworks, such as Langchain and Streamlit, to make it easier to build and deploy LLM-powered applications.</li></ul><p id="b505" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">By taking advantage of the integrations available for LLamaindex, you can build more powerful, versatile, and insightful LLM-powered applications.</p><h1 id="87b0" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">LangChain</strong></h1><p id="2d81" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj">In the ever-evolving landscape of artificial intelligence, large language models (LLMs) have emerged as a transformative force, capable of generating human-quality text, answering questions, and more. However, harnessing their full potential can be a complex endeavor. This is where LangChain steps in, offering a robust framework that simplifies the development and deployment of LLM-powered applications.</p><p id="aeb3" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">While LLamaIndex focuses on bridging the gap between your data and LLMs, LangChain provides a different perspective. It offers a modular and extensible architecture that empowers developers to seamlessly combine LLMs with various data sources and services. This flexibility enables the creation of a wide range of applications that leverage the unique capabilities of LLMs.</p><p id="db75" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">At its core, LangChain consists of reusable components, including prompt templates, support for various LLMs such as OpenAI API, Bard, and Bloom, dynamic agents, and chains. These components can be artfully assembled to create complex LLM-powered applications, ranging from chatbots engaging in natural conversations to virtual assistants, content generation tools, and educational resources.</p><p id="4ae0" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">LangChain is a versatile tool that, like LLamaIndex, unlocks the potential of LLMs but with a distinct focus on the application development process. Its modular and extensible architecture makes it easy for developers to create diverse LLM-powered applications. In the upcoming sections, we’ll delve deeper into LangChain’s features and explore the myriad possibilities it offers for LLM-powered applications.</p></div></div></div><div class="ab ca nd ne nf ng" role="separator"><span class="nh bx bl ni nj nk"></span><span class="nh bx bl ni nj nk"></span><span class="nh bx bl ni nj"></span></div><div class="eo ep eq er es"><div class="ab ca"><div class="ch bg dx dy dz ea"><h1 id="1917" class="ku kv ev be kw kx nl kz la lb nm ld le lf nn lh li lj no ll lm ln np lp lq lr bj">Tools offered by Langchain:</h1><h1 id="6849" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">Model I/O:</strong></h1><figure class="nt nu nv nw nx ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa go ob bg oc"><div class="nq nr ns"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*Qk7PU6HYRVomP0ZE 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*Qk7PU6HYRVomP0ZE 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*Qk7PU6HYRVomP0ZE 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*Qk7PU6HYRVomP0ZE 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*Qk7PU6HYRVomP0ZE 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*Qk7PU6HYRVomP0ZE 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Qk7PU6HYRVomP0ZE 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*Qk7PU6HYRVomP0ZE 640w, https://miro.medium.com/v2/resize:fit:720/0*Qk7PU6HYRVomP0ZE 720w, https://miro.medium.com/v2/resize:fit:750/0*Qk7PU6HYRVomP0ZE 750w, https://miro.medium.com/v2/resize:fit:786/0*Qk7PU6HYRVomP0ZE 786w, https://miro.medium.com/v2/resize:fit:828/0*Qk7PU6HYRVomP0ZE 828w, https://miro.medium.com/v2/resize:fit:1100/0*Qk7PU6HYRVomP0ZE 1100w, https://miro.medium.com/v2/resize:fit:1400/0*Qk7PU6HYRVomP0ZE 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="https://python.langchain.com/docs/modules/model_io/" class="bg kb od c" width="700" height="269" loading="eager"/></picture></div></div></figure><p id="488f" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">When it comes to harnessing the potential of large language models (LLMs) through LangChain, the Module Model I/O (Input/Output) stands as a pivotal core component. This feature offers a standardized and user-friendly method of interacting with LLMs, making it easier for developers to create LLM-powered applications that can tackle real-world challenges. The Module Model I/O comprises three key elements:</p><p id="46f6" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Prompts:</strong> These are like instructions for LLMs, telling them what to do and how to do it. For instance, a prompt could guide an LLM to generate a poem, translate a sentence, or answer a question.</p><p id="6030" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Language Models:</strong> Think of these as the engines behind LangChain applications. They’re responsible for tasks such as text generation, language translation, and providing answers to queries. LangChain offers support for a wide array of LLMs, including popular ones like the OpenAI API, Bard, and Bloom.</p><p id="e03b" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Input Parsers: Input parsers work their magic by converting user input into a format that LLMs can understand. For example, they can take a natural language question and transform it into a structured query for database searches.</p><p id="bafa" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">The Module Model I/O provides numerous advantages for developers:</strong></p><p id="b48e" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Standardization:</strong> By offering a standardized way to interact with LLMs, it simplifies the process of building and maintaining LLM-powered applications.</p><p id="747b" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Flexibility:</strong> This feature is incredibly versatile, accommodating a diverse range of LLMs and input formats. Developers have the freedom to choose the tools that best suit their specific needs.</p><p id="8c11" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Extensibility:</strong> Developers can take customization to the next level. The Module Model I/O is extensible, allowing the creation of unique prompts, language models, and input parsers, which is perfect for tailoring LLM-powered applications to meet the precise requirements of users.</p><h1 id="dc2a" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">Retrieval:</strong></h1><figure class="nt nu nv nw nx ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa go ob bg oc"><div class="nq nr ns"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*64xqbKMkJDaRwuQY 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*64xqbKMkJDaRwuQY 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*64xqbKMkJDaRwuQY 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*64xqbKMkJDaRwuQY 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*64xqbKMkJDaRwuQY 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*64xqbKMkJDaRwuQY 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*64xqbKMkJDaRwuQY 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*64xqbKMkJDaRwuQY 640w, https://miro.medium.com/v2/resize:fit:720/0*64xqbKMkJDaRwuQY 720w, https://miro.medium.com/v2/resize:fit:750/0*64xqbKMkJDaRwuQY 750w, https://miro.medium.com/v2/resize:fit:786/0*64xqbKMkJDaRwuQY 786w, https://miro.medium.com/v2/resize:fit:828/0*64xqbKMkJDaRwuQY 828w, https://miro.medium.com/v2/resize:fit:1100/0*64xqbKMkJDaRwuQY 1100w, https://miro.medium.com/v2/resize:fit:1400/0*64xqbKMkJDaRwuQY 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="https://python.langchain.com/docs/modules/data_connection/" class="bg kb od c" width="700" height="242" loading="lazy"/></picture></div></div></figure><p id="7de5" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">In this amazing world of Large Language Model (LLM) applications, there’s often a need for personalized data that goes beyond what these models were originally trained on. It’s like asking an artist to paint a picture with colors they’ve never seen before. This mystical feat is achieved through the mystical process of Retrieval Augmented Generation (RAG), where external data is summoned and handed over to the LLM during the creation phase.</p><p id="6350" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Now, imagine LangChain as your mystical wand, offering all the enchanting building blocks for RAG applications. From the simplest spells to the most intricate incantations, LangChain has it all covered. In this chapter of our magical documentation, we’ll delve into the art of retrieval — the process of summoning the data. But be warned, though it may sound simple, this sorcery holds subtle complexities and a treasure trove of secrets, entailing the use of several mystical modules.</p><p id="0104" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Document Loaders: </strong>These serve as the gateways to a vast realm of knowledge within LangChain. With over a hundred document loaders at your disposal, as well as connections to other prominent knowledge hubs like AirByte and Unstructured, you gain access to a library teeming with diverse documents. Whether they’re written in the HTML scrolls of the internet’s ancient past, the enigmatic symbols of PDFs, or the cryptic code runes, you can fetch them from both hidden s3 treasure troves and publicly accessible websites.</p><p id="7696" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Document Transformers: </strong>These components are the architects of data refinement. Their primary function is to split or chunk large documents into smaller, more digestible sections. LangChain offers an array of algorithms tailored for this task, each fine-tuned to handle specific document types, whether it’s the intricate language of code or the mystical world of markdown.</p><p id="e6f6" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Text Embedding Models: </strong>In the art of data retrieval, creating text embeddings is essential. These embeddings capture the essence of a text’s meaning, facilitating the discovery of related content. LangChain seamlessly integrates with over 25 different embedding providers and methods, ranging from open-source to proprietary API, giving you the flexibility to choose the one that best aligns with your project. Moreover, LangChain offers a standardized interface for easy model switching.</p><p id="0ffe" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Vector Stores: </strong>With the advent of embeddings, the need for efficient storage and retrieval mechanisms has grown. LangChain offers connections to over 50 distinct vector stores, from open-source local options to cloud-hosted proprietary solutions. This flexibility enables you to select the one that best suits your requirements, with the assurance of a standardized interface for smooth transitions.</p><p id="d873" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Retrievers: </strong>Your journey doesn’t end with storage; you need retrieval methods to access your data. LangChain provides support for various retrieval algorithms, from straightforward semantic searches to advanced techniques that enhance performance.</p><p id="4471" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Parent Document Retriever: </strong>Think of this as a feature that allows you to explore not just individual documents, but also the larger context they belong to. It enables the creation of multiple retrievable sections within a single document, allowing you to navigate through both the details and the broader narrative.</p><p id="8938" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Self-Query Retriever: </strong>User queries are often a blend of straightforward requests and underlying metadata. The Self Query Retriever helps you extract the semantic essence of a query from the additional metadata and logic woven into it.</p><p id="b7f2" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Ensemble Retriever: </strong>Just like musicians in an orchestra, the Ensemble Retriever brings together documents from various sources and retrieval algorithms, blending them into a harmonious medley to enrich your data exploration.</p><h1 id="b28c" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">Chains:</strong></h1><p id="cbb3" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj">While using a Large Language Model (LLM) in isolation can handle simple tasks, more intricate applications demand the art of chaining LLMs, whether it’s LLMs working together or collaborating with other essential components.</p><p id="96bb" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">LangChain unveils two overarching frameworks for this enchanting process. The traditional method involves using the Chain interface, while the contemporary approach employs the LangChain Expression Language (LCEL). For those embarking on new applications, LCEL reigns supreme for chain composition. However, we treasure several invaluable pre-built Chains, and we continue to support them, ensuring that both frameworks coexist harmoniously. As we journey onward, we’ll discover that Chains can even become integral elements within LCEL, proving that the two are not mutually exclusive. So, let’s embark on this magical journey into the world of Chains in LangChain.</p><p id="27f9" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Async API:</strong> The LangChain Async API introduces the ability to run LangChain Chains asynchronously, a valuable feature for enhancing the performance of chains with multiple intricate steps, such as document retrieval, translation, and summarization. Imagine the power of seamlessly orchestrating these actions.</p><p id="602c" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Different Call Methods:</strong> LangChain Chains are at your beck and call through a variety of methods. The simplest path involves directly invoking the Chain.run() method. For those seeking more flexibility, the LangChain AgentExecutor offers a comprehensive approach, allowing you to chain chains together and execute them in parallel. The LangChain SDK provides a high-level API for both constructing and executing chains, simplifying the complex orchestration of your magical workflows.</p><p id="41d6" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Custom Chain:</strong> Your creativity knows no bounds in LangChain. The creation of custom chains allows you to craft unique workflows tailored to your needs, perfect for those intricate tasks that go beyond the realm of built-in chains. It’s like wielding the wand of customization in the world of chains.</p><p id="70d5" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Adding Memory (State):</strong> Imagine granting LangChain Chains the ability to remember past actions and conversations. With memory (state) augmentation, chains can seamlessly store and retrieve information between steps. This proves invaluable for tasks like maintaining conversation flow or tracking the progress of a complex chain, making your chains smarter and more intuitive.</p><p id="5780" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Using OpenAI Functions:</strong> LangChain Chains have the magical ability to call upon OpenAI functions, pre-trained machine learning models with the power to perform a myriad of tasks, including text generation, translation, and question answering. Moreover, you can seamlessly integrate the results of OpenAI functions into other steps within the chain, creating a seamless flow of information and action.</p><h1 id="8583" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">Memory:</strong></h1><figure class="nt nu nv nw nx ny nq nr paragraph-image"><div role="button" tabindex="0" class="nz oa go ob bg oc"><div class="nq nr ns"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*JC7MvW06ViVKON7F 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*JC7MvW06ViVKON7F 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*JC7MvW06ViVKON7F 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*JC7MvW06ViVKON7F 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*JC7MvW06ViVKON7F 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*JC7MvW06ViVKON7F 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JC7MvW06ViVKON7F 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*JC7MvW06ViVKON7F 640w, https://miro.medium.com/v2/resize:fit:720/0*JC7MvW06ViVKON7F 720w, https://miro.medium.com/v2/resize:fit:750/0*JC7MvW06ViVKON7F 750w, https://miro.medium.com/v2/resize:fit:786/0*JC7MvW06ViVKON7F 786w, https://miro.medium.com/v2/resize:fit:828/0*JC7MvW06ViVKON7F 828w, https://miro.medium.com/v2/resize:fit:1100/0*JC7MvW06ViVKON7F 1100w, https://miro.medium.com/v2/resize:fit:1400/0*JC7MvW06ViVKON7F 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="https://python.langchain.com/assets/images/memory_diagram-0627c68230aa438f9b5419064d63cbbc.png" class="bg kb od c" width="700" height="358" loading="lazy"/></picture></div></div></figure><p id="d659" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">In the mystical realm of Large Language Models (LLMs), conversational applications reign supreme. Within the tapestry of these conversations, a crucial element is the ability to reference information from earlier parts of the exchange. This ability to store and recall past interactions is aptly named “memory.” LangChain, the magical framework, offers an array of tools and utilities to infuse your systems with the gift of memory. Whether your needs are straightforward or intricate, LangChain’s memory system can be seamlessly integrated into chains, offering a dynamic blend of reading and writing actions. The knowledge within memory serves as a guiding light for LangChain Chains, ensuring they draw upon past interactions to enhance their responses.</p><p id="7b1d" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Memory systems are shaped by two core design decisions: how state is stored and how it is queried. Underneath the mystical veil of memory lies a historical record of chat messages, meticulously preserved in various forms, from in-memory lists to resilient databases. The act of querying this knowledge reveals a rich tapestry, and the memory module boasts a repertoire of data structures and algorithms that provide unique perspectives on this trove of wisdom.</p><p id="e684" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">With LangChain, the possibilities for memory are endless. You can build a simple memory system that retrieves the most recent messages or opt for a more complex setup that extracts entities from stored messages and provides information relevant to the current conversation. Each application has its unique memory requirements, and the memory module offers both simplicity for beginners and the flexibility to craft custom systems when the need arises.</p><p id="26de" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">In this enchanted journey into LangChain Memory, we’ll uncover the art of storing and querying memories, understanding the variables they return, and the different ways memory can be harnessed within chains. So, let’s embark on this magical expedition to reveal the true essence of memory in LangChain.</p><h1 id="372f" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">Agents:</strong></h1><p id="a5a7" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj">In the enchanting world of LangChain, Agents emerge as powerful entities, wielding the magical essence of Large Language Models (LLMs) to orchestrate sequences of actions. Unlike conventional chains, where actions are preordained in code, Agents harness the reasoning capabilities of a language model to dynamically determine the next steps and their order. Within this mystical realm, some crucial terminologies and schemas await your exploration:</p><p id="3907" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Agent Action:</strong> These are like incantations that guide an agent’s actions. Each AgentAction consists of a tool property (the tool to be invoked) and a tool_input property (the input for that tool).</p><p id="0641" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Agent Finish:</strong> This signifies the end of an agent’s task, marked by a return_values parameter, typically containing an output (usually a string) that is to be returned.</p><p id="3bcb" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><strong class="lu ew">Intermediate Steps:</strong> These represent past agent actions and their corresponding outcomes, allowing the agent to keep track of its progress. These steps are like chapters in the agent’s book of spells and are essential for guiding future iterations.</p><p id="c8a8" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Agents, the orchestrators of magic, are chains imbued with the power to decide the next course of action. They are fueled by a language model and a prompt, receiving inputs such as the list of available tools, user queries, and the history of previous actions. In return, agents conjure up either the next action to take (AgentAction) or the final response to be conveyed to the user (AgentFinish).</p><p id="2145" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">At the heart of an agent’s power are its tools — functions that the agent calls upon. Yet, the key to the agent’s success lies in providing access to the right tools and crafting their descriptions to align perfectly with the agent’s needs. LangChain, like a treasure chest of magical artifacts, offers a wide range of tools to begin your journey and also empowers you to define custom tools with personalized descriptions.</p><p id="c7f4" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Toolkits, akin to a magician’s collection of spell books, encompass groups of tools needed to achieve specific objectives. These toolkits, often composed of 3–5 essential tools, hold the key to an agent’s versatility, allowing them to take on various quests.</p><p id="23be" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">The AgentExecutor serves as the runtime for agents, enacting the agent’s decisions and executing their actions. This runtime handles complexities such as non-existent tools, tool errors, and unparseable agent output, ensuring a smooth magical performance. There are other experimental runtimes supported as well, each carrying its unique flavor of enchantment.</p><p id="6bba" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">In this magical journey of unraveling LangChain Agents, we will delve into building an agent from scratch using LangChain Expression Language, crafting custom tools, and running the agent within a custom loop. We will also uncover the power of memory in enabling seamless conversations with the agent, adding depth and context to your interactions. So, prepare to embark on this enchanting expedition into the realm of LangChain Agents.</p></div></div></div><div class="ab ca nd ne nf ng" role="separator"><span class="nh bx bl ni nj nk"></span><span class="nh bx bl ni nj nk"></span><span class="nh bx bl ni nj"></span></div><div class="eo ep eq er es"><div class="ab ca"><div class="ch bg dx dy dz ea"><h1 id="e69d" class="ku kv ev be kw kx nl kz la lb nm ld le lf nn lh li lj no ll lm ln np lp lq lr bj">Key Applications</h1><h1 id="10f4" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">LangChain:</strong></h1><blockquote class="oe of og"><p id="10f6" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Text generation</p><p id="c1e3" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Translation</p><p id="8e00" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Question answering</p><p id="76dd" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Summarization</p><p id="afb5" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Classification</p></blockquote><h1 id="a2df" class="ku kv ev be kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bj"><strong class="al">LlamaIndex:</strong></h1><blockquote class="oe of og"><p id="a4a2" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Document search and retrieval</p><p id="46b5" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">LLM augmentation</p><p id="151a" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Chatbots and virtual assistants</p><p id="e7e0" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Data analytics</p><p id="4d15" class="ls lt oh lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj">Content generation</p></blockquote></div></div></div><div class="ab ca nd ne nf ng" role="separator"><span class="nh bx bl ni nj nk"></span><span class="nh bx bl ni nj nk"></span><span class="nh bx bl ni nj"></span></div><div class="eo ep eq er es"><div class="ab ca"><div class="ch bg dx dy dz ea"><h1 id="9cb6" class="ku kv ev be kw kx nl kz la lb nm ld le lf nn lh li lj no ll lm ln np lp lq lr bj">Summary</h1><p id="2159" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj">In the world of data and language tools, we have two strong contenders: LlamaIndex and LangChain. LlamaIndex boasts impressive speed and accuracy, making it excellent for tasks like document search and enhancing large language models. It’s like a superhero for handling customer support, code generation, and chatbots efficiently. On the other hand, LangChain offers flexibility and versatility, serving as a multi-talented tool with an extensible nature. It’s easier to use with a simple interface and abundant documentation. Additionally, LangChain is compatible with a broader range of language models. You can leverage LangChain for creating chatbots with various capabilities, including poetry generation, language translation, and code creation across multiple programming languages. In this comparison, LlamaIndex excels in data indexing and language model enhancement, while LangChain stands out for its versatility and adaptability in building robust applications with large language models.</p><h2 id="c141" class="oi kv ev be kw oj ok ol la om on oo le md op oq or mh os ot ou ml ov ow ox oy bj">References:</h2><p id="befd" class="pw-post-body-paragraph ls lt ev lu b lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp eo bj"><a class="af oz" href="https://python.langchain.com/docs/get_started/introduction" rel="noopener ugc nofollow" target="_blank">Langchain Documentation</a></p><p id="9f00" class="pw-post-body-paragraph ls lt ev lu b lv mq lx ly lz mr mb mc md ms mf mg mh mt mj mk ml mu mn mo mp eo bj"><a class="af oz" href="https://docs.llamaindex.ai/en/v0.8.36/" rel="noopener ugc nofollow" target="_blank">LLamaIndex Documentation</a></p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg dx dy dz ea"></div></div></div><div class="ab ca"><div class="ch bg dx dy dz ea"><div class="pa pb ab hf"><div class="pc ab"><a class="pd ax am ao" rel="noopener follow" href="/tag/langchain?source=post_page-----4900989752ac---------------langchain-----------------"><div class="pe go cw pf ed pg ph be b bf z bj pi">Langchain</div></a></div><div class="pc ab"><a class="pd ax am ao" rel="noopener follow" href="/tag/llamaindex?source=post_page-----4900989752ac---------------llamaindex-----------------"><div class="pe go cw pf ed pg ph be b bf z bj pi">Llamaindex</div></a></div><div class="pc ab"><a class="pd ax am ao" rel="noopener follow" href="/tag/llm?source=post_page-----4900989752ac---------------llm-----------------"><div class="pe go cw pf ed pg ph be b bf z bj pi">Llm</div></a></div><div class="pc ab"><a class="pd ax am ao" rel="noopener follow" href="/tag/artificial-intelligence?source=post_page-----4900989752ac---------------artificial_intelligence-----------------"><div class="pe go cw pf ed pg ph be b bf z bj pi">Artificial Intelligence</div></a></div><div class="pc ab"><a class="pd ax am ao" rel="noopener follow" href="/tag/technology?source=post_page-----4900989752ac---------------technology-----------------"><div class="pe go cw pf ed pg ph be b bf z bj pi">Technology</div></a></div></div></div></div><div class="l"></div><footer class="pj pk pl pm pn po pp pq pr ab q ps pt c"><div class="l ae"><div class="ab ca"><div class="ch bg dx dy dz ea"><div class="ab co pu"><div class="ab q iq"><div class="pv l"><span class="l pw px py e d"><div class="ab q iq"><div class="pw-multi-vote-icon go ir is it iu"><div class=""><div class="iv iw ix iy iz ja jb am jc jd je iu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM15.42 1.84l-1.18-.39-.34 2.5 1.52-2.1zM9.76 1.45l-1.19.4 1.53 2.1-.34-2.5zM20.25 11.84l-2.5-4.4a1.42 1.42 0 0 0-.93-.64.96.96 0 0 0-.75.18c-.25.19-.4.42-.45.7l.05.05 2.35 4.13c1.62 2.95 1.1 5.78-1.52 8.4l-.46.41c1-.13 1.93-.6 2.78-1.45 2.7-2.7 2.51-5.59 1.43-7.38zM12.07 9.01c-.13-.69.08-1.3.57-1.77l-2.06-2.07a1.12 1.12 0 0 0-1.56 0c-.15.15-.22.34-.27.53L12.07 9z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.74 8.3a1.13 1.13 0 0 0-.73-.5.67.67 0 0 0-.53.13c-.15.12-.59.46-.2 1.3l1.18 2.5a.45.45 0 0 1-.23.76.44.44 0 0 1-.48-.25L7.6 6.11a.82.82 0 1 0-1.15 1.15l3.64 3.64a.45.45 0 1 1-.63.63L5.83 7.9 4.8 6.86a.82.82 0 0 0-1.33.9c.04.1.1.18.18.26l1.02 1.03 3.65 3.64a.44.44 0 0 1-.15.73.44.44 0 0 1-.48-.1L4.05 9.68a.82.82 0 0 0-1.4.57.81.81 0 0 0 .24.58l1.53 1.54 2.3 2.28a.45.45 0 0 1-.64.63L3.8 13a.81.81 0 0 0-1.39.57c0 .22.09.43.24.58l4.4 4.4c2.8 2.8 5.5 4.12 8.68.94 2.27-2.28 2.71-4.6 1.34-7.1l-2.32-4.08z"></path></svg></div></div></div><div class="pw-multi-vote-count l jf jg jh ji jj jk jl"><p class="be b jm z gw"><span class="iw">--</span></p></div></div></span><span class="l h g f pz qa"><div class="ab q iq"><div class="pw-multi-vote-icon go ir is it iu"><div class=""><div class="iv iw ix iy iz ja jb am jc jd je iu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM15.42 1.84l-1.18-.39-.34 2.5 1.52-2.1zM9.76 1.45l-1.19.4 1.53 2.1-.34-2.5zM20.25 11.84l-2.5-4.4a1.42 1.42 0 0 0-.93-.64.96.96 0 0 0-.75.18c-.25.19-.4.42-.45.7l.05.05 2.35 4.13c1.62 2.95 1.1 5.78-1.52 8.4l-.46.41c1-.13 1.93-.6 2.78-1.45 2.7-2.7 2.51-5.59 1.43-7.38zM12.07 9.01c-.13-.69.08-1.3.57-1.77l-2.06-2.07a1.12 1.12 0 0 0-1.56 0c-.15.15-.22.34-.27.53L12.07 9z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.74 8.3a1.13 1.13 0 0 0-.73-.5.67.67 0 0 0-.53.13c-.15.12-.59.46-.2 1.3l1.18 2.5a.45.45 0 0 1-.23.76.44.44 0 0 1-.48-.25L7.6 6.11a.82.82 0 1 0-1.15 1.15l3.64 3.64a.45.45 0 1 1-.63.63L5.83 7.9 4.8 6.86a.82.82 0 0 0-1.33.9c.04.1.1.18.18.26l1.02 1.03 3.65 3.64a.44.44 0 0 1-.15.73.44.44 0 0 1-.48-.1L4.05 9.68a.82.82 0 0 0-1.4.57.81.81 0 0 0 .24.58l1.53 1.54 2.3 2.28a.45.45 0 0 1-.64.63L3.8 13a.81.81 0 0 0-1.39.57c0 .22.09.43.24.58l4.4 4.4c2.8 2.8 5.5 4.12 8.68.94 2.27-2.28 2.71-4.6 1.34-7.1l-2.32-4.08z"></path></svg></div></div></div><div class="pw-multi-vote-count l jf jg jh ji jj jk jl"><p class="be b jm z gw"><span class="iw">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao iv jp jq ab q jr js jt" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="jo"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z gw"><span class="pw-responses-count jn jo">1</span></p></button></div></div></div></div><div class="ab q"><div class="nk l hc"></div><div class="nk l hc"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af jr ah ai aj ak al kc an ao ap gz kd ke jt kf"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="qb qc qd qe qf l bw"><div class="ab ca"><div class="ch bg dx dy dz ea"><div class="ck ab qg co"><div class="ab gg"><a rel="noopener follow" href="/@zahidali133?source=post_page-----4900989752ac--------------------------------"><div class="l qh qi bx qj gk"><div class="l go"><img alt="Zahid Ali" class="l ec bx qk ql cw" src="https://miro.medium.com/v2/resize:fill:144:144/1*tJ2LDg0bvxvOhOqdpc-EJA.jpeg" width="72" height="72" loading="lazy"/><div class="gl bx l qk ql eh n gm gn"></div></div></div></a></div><div class="j i d"><div class="ab"><span><button class="be b bf z qm pe qn qo qp qq qr qs qt gz qu qv qw qx qy qz ec bl ra rb">Follow</button></span><div class="rc l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6e2fac763e07&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40zahidali133%2Fcomparison-of-llamaindex-and-langchain-4900989752ac&amp;newsletterV3=8ecd3d43dbb4&amp;newsletterV3Id=6e2fac763e07&amp;user=Zahid+Ali&amp;userId=8ecd3d43dbb4&amp;source=-----4900989752ac---------------------subscribe_user-----------"><button class="be b bf z rg am rh ri rj rk rl rm rn ro qt gz qu qv qw qy qz ec bl ra rb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="rd re rf"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" rel="noopener follow" href="/@zahidali133?source=post_page-----4900989752ac--------------------------------"><h2 class="pw-author-name be rp rq rr rs bj"><span class="eo">Written by <!-- -->Zahid Ali</span></h2></a></div><div class="pc ab"><div class="l hc"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar gt" rel="noopener follow" href="/@zahidali133/followers?source=post_page-----4900989752ac--------------------------------">16 Followers</a></span></div></div><div class="rt l"><p class="be b bf z bj"><span class="eo">Fullstack Developer, LLM Ops, Software Engineer</span></p></div></div><div class="h k"><div class="ab"><span><button class="be b bf z qm pe qn qo qp qq qr qs qt gz qu qv qw qx qy qz ec bl ra rb">Follow</button></span><div class="rc l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6e2fac763e07&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40zahidali133%2Fcomparison-of-llamaindex-and-langchain-4900989752ac&amp;newsletterV3=8ecd3d43dbb4&amp;newsletterV3Id=6e2fac763e07&amp;user=Zahid+Ali&amp;userId=8ecd3d43dbb4&amp;source=-----4900989752ac---------------------subscribe_user-----------"><button class="be b bf z rg am rh ri rj rk rl rm rn ro qt gz qu qv qw qy qz ec bl ra rb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="rd re rf"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ru bg rv rw rx ry rz sa"></div></div></div><div class="h k j"><div class="ru bg rv sb"></div><div class="ab ca"><div class="ch bg dx dy dz ea"><div class="sc ab iq hf"><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">Help</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">Status</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">About</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----4900989752ac--------------------------------"><p class="be b jm z gw">Careers</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">Blog</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">Privacy</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">Terms</p></a></div><div class="sd se l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----4900989752ac--------------------------------" rel="noopener follow"><p class="be b jm z gw">Text to speech</p></a></div><div class="sd l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/business?source=post_page-----4900989752ac--------------------------------"><p class="be b jm z gw">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20231206-185151-79201779e9"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-4900989752ac","user-8ecd3d43dbb4"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"inDisabledExperiment":false,"loHomepageEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":true,"isSafari":true,"isFirefox":false,"routingEntity":{"type":"DEFAULT","explicit":false},"viewerIsBot":false},"debug":{"requestId":"8523e922-25db-49dc-9e27-7e20e57ffb03","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"12c9de702d285429","ot-tracer-traceid":"39bdb656b2b03cd8","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002F@zahidali133\u002Fcomparison-of-llamaindex-and-langchain-4900989752ac","host":"medium.com","hostname":"medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20231206-185151-79201779e9","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20231206-185151-79201779e9","commit":"79201779e91462726c6804f77456c0b61925aa22"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","isLoggedIn":false,"variantFlagWithCustomIDs({\"input\":{\"flagName\":\"exclude_post_page_recirc_in_ssr\",\"postId\":\"4900989752ac\"}})":{"__typename":"VariantFlag","name":"exclude_post_page_recirc_in_ssr","valueType":{"__typename":"VariantFlagBoolean","value":true}},"collectionByDomainOrSlug({\"domainOrSlug\":\"medium.com\"})":null,"postResult({\"id\":\"4900989752ac\"})":{"__ref":"Post:4900989752ac"}},"LinkedAccounts:8ecd3d43dbb4":{"__typename":"LinkedAccounts","mastodon":null,"id":"8ecd3d43dbb4"},"UserViewerEdge:userId:8ecd3d43dbb4-viewerId:lo_231753d68df8":{"__typename":"UserViewerEdge","id":"userId:8ecd3d43dbb4-viewerId:lo_231753d68df8","isFollowing":false,"isUser":false},"NewsletterV3:6e2fac763e07":{"__typename":"NewsletterV3","id":"6e2fac763e07","type":"NEWSLETTER_TYPE_AUTHOR","slug":"8ecd3d43dbb4","name":"8ecd3d43dbb4","collection":null,"user":{"__ref":"User:8ecd3d43dbb4"}},"User:8ecd3d43dbb4":{"__typename":"User","id":"8ecd3d43dbb4","name":"Zahid Ali","username":"zahidali133","newsletterV3":{"__ref":"NewsletterV3:6e2fac763e07"},"linkedAccounts":{"__ref":"LinkedAccounts:8ecd3d43dbb4"},"isSuspended":false,"imageId":"1*tJ2LDg0bvxvOhOqdpc-EJA.jpeg","mediumMemberAt":0,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":16},"customDomainState":null,"hasSubdomain":false,"bio":"Fullstack Developer, LLM Ops, Software Engineer","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:8ecd3d43dbb4-viewerId:lo_231753d68df8"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":null,"twitterScreenName":"zahidali133"},"Paragraph:09550dc2c048_0":{"__typename":"Paragraph","id":"09550dc2c048_0","name":"78c1","type":"H3","href":null,"layout":null,"metadata":null,"text":"Comparison of LLamaIndex and LangChain","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_1":{"__typename":"Paragraph","id":"09550dc2c048_1","name":"65c1","type":"H3","href":null,"layout":null,"metadata":null,"text":"General Overview","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_2":{"__typename":"Paragraph","id":"09550dc2c048_2","name":"f09c","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLamaIndex","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_3":{"__typename":"Paragraph","id":"09550dc2c048_3","name":"d577","type":"P","href":null,"layout":null,"metadata":null,"text":"LLamaIndex is the essential bridge between your data and powerful language models (LLMs), streamlining data tasks with user-friendly features. It allows you to create organized data indexes, leverage multiple LLMs with diverse strengths, augment your data for improved LLM performance, and easily query your data using natural language. If you’re looking to unlock the full potential of your LLMs for document-based tasks, LLamaIndex is the game-changing solution, making data-driven insights more accessible and efficient, ensuring your data works harder for you.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_4":{"__typename":"Paragraph","id":"09550dc2c048_4","name":"ba37","type":"H3","href":null,"layout":null,"metadata":null,"text":"Tools offered by LLamaIndex:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":28,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_5":{"__typename":"Paragraph","id":"09550dc2c048_5","name":"282d","type":"P","href":null,"layout":null,"metadata":null,"text":"Data Connectors: Data connectors are the unsung heroes of data integration, simplifying the complex task of bridging the gap between your data sources and your data repository. Without them, manual data extraction, transformation, and loading (ETL) would be a cumbersome and error-prone process. These connectors offer a seamless way to ingest data directly from its native source and format, eliminating the need for time-consuming data conversion. Furthermore, data connectors come with a host of advantages, such as automatically enhancing data quality, securing data through encryption, boosting data performance via caching, and reducing the maintenance efforts required for your data integration solution. If you’re seeking to streamline your data integration process, data connectors provide a flexible and scalable solution to maximize the potential of your data. So, remember to credit these essential tools for making efficient data integration a reality.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_6":{"__typename":"Paragraph","id":"09550dc2c048_6","name":"fbdd","type":"P","href":null,"layout":null,"metadata":null,"text":"Data Indexes: Think of an index like the super-speedy assistant for your data searches. It’s what makes LlamaIndex work seamlessly for question-answering and chat functions with your data. These indexes are built from your documents and make it possible for you to ask questions or have conversations with your data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_7":{"__typename":"Paragraph","id":"09550dc2c048_7","name":"0046","type":"P","href":null,"layout":null,"metadata":null,"text":"Behind the scenes, these indexes are like puzzle pieces, representing parts of your original documents. They also have special tools to make data retrieval smoother and more efficient, kind of like having an automatic search feature. So, even though they might seem technical, indexes are the key to making your experience with LlamaIndex simple and user-friendly when working with your data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_8":{"__typename":"Paragraph","id":"09550dc2c048_8","name":"b1f5","type":"P","href":null,"layout":null,"metadata":null,"text":"Engines: LLamaIndex Engines are the magic behind making data and large language models (LLMs) work together seamlessly. They provide a flexible framework to connect LLMs to various data sources, making it simple for them to access real-world information. At their core, these engines feature a clever search system that understands natural language queries, making data interaction a breeze. But that’s not all — they can also organize your data for faster access, add extra information to improve your LLM-powered applications, and help you choose the right LLM for the job. In a nutshell, LLamaIndex Engines are the key to creating a wide range of LLM-powered applications, serving as the bridge between data and LLMs to tackle real-world challenges.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_9":{"__typename":"Paragraph","id":"09550dc2c048_9","name":"eae3","type":"P","href":null,"layout":null,"metadata":null,"text":"Data Agents: Data Agents, the brainy LLM-powered knowledge workers within LlamaIndex, are the ultimate multitaskers when it comes to managing your data. They possess the unique ability to intelligently sift through unstructured, semi-structured, and structured data sources, as well as interact with external service APIs in an organized manner, all while handling both “read” and “write” operations. This versatility makes them indispensable for automating data-related tasks. Unlike query engines that are limited to “reading” data from static sources, Data Agents can dynamically ingest and modify data from various tools, making them highly adaptable to evolving data environments. Building a Data Agent involves defining a reasoning loop for decision-making and creating tool abstractions to provide a consistent interface for interacting with different tools. LlamaIndex supports two types of Data Agents: OpenAI Function agents, based on the OpenAI Function API, and ReAct agents, which can collaborate with any chat\u002Ftext completion endpoint. In essence, Data Agents bring together the prowess of LLMs and the flexibility of tool abstractions to usher in a new era of automation and intelligence within your data workflows.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_10":{"__typename":"Paragraph","id":"09550dc2c048_10","name":"8fa7","type":"P","href":null,"layout":null,"metadata":null,"text":"Application Integrations: LLamaIndex is a powerful tool for building large language model (LLM)-powered applications. However, its true potential is unlocked through its extensive integrations with other tools and services.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_11":{"__typename":"Paragraph","id":"09550dc2c048_11","name":"707a","type":"P","href":null,"layout":null,"metadata":null,"text":"These integrations make it easy to connect LLamaindex to a wide range of data sources, observability tools, and application frameworks. This allows you to build more powerful and versatile LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_12":{"__typename":"Paragraph","id":"09550dc2c048_12","name":"aab9","type":"P","href":null,"layout":null,"metadata":null,"text":"For example, LLamaindex can be integrated with vector stores, such as Pinecone and Milvus, to enable efficient search and retrieval of similar documents. It can also be integrated with tracing tools, such as Graphsignal, to provide insights into the inner workings of LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_13":{"__typename":"Paragraph","id":"09550dc2c048_13","name":"ea69","type":"P","href":null,"layout":null,"metadata":null,"text":"In addition, LLamaindex can be integrated with application frameworks, such as Langchain and Streamlit, to make it easier to build and deploy LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_14":{"__typename":"Paragraph","id":"09550dc2c048_14","name":"ab2e","type":"P","href":null,"layout":null,"metadata":null,"text":"Overall, the integrations available for LLamaindex make it a powerful and versatile tool for building a wide range of LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_15":{"__typename":"Paragraph","id":"09550dc2c048_15","name":"0df4","type":"P","href":null,"layout":null,"metadata":null,"text":"Here are some specific examples of LLamaindex integrations:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_16":{"__typename":"Paragraph","id":"09550dc2c048_16","name":"e9eb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Data loaders: LLamaindex can be integrated with a variety of data loaders, such as Airbyte and Poe, to make it easy to ingest data from a variety of sources.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_17":{"__typename":"Paragraph","id":"09550dc2c048_17","name":"32bf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Agent tools: LLamaindex can be integrated with a variety of agent tools, such as ChatGPT plugins and OpenAI Function Calling, to extend the capabilities of Data Agents.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_18":{"__typename":"Paragraph","id":"09550dc2c048_18","name":"e24b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Observability\u002Ftracing\u002Fevaluation: LLamaindex can be integrated with a variety of observability\u002Ftracing\u002Fevaluation tools, such as Graphsignal, TruLens, and DeepEval, to provide insights into the performance of LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_19":{"__typename":"Paragraph","id":"09550dc2c048_19","name":"fa12","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Structured outputs: LLamaindex can be integrated with a variety of structured output formats, such as CSV, JSON, and SQL, to make it easy to consume the results of LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_20":{"__typename":"Paragraph","id":"09550dc2c048_20","name":"52d1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Application frameworks: LLamaindex can be integrated with a variety of application frameworks, such as Langchain and Streamlit, to make it easier to build and deploy LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_21":{"__typename":"Paragraph","id":"09550dc2c048_21","name":"b505","type":"P","href":null,"layout":null,"metadata":null,"text":"By taking advantage of the integrations available for LLamaindex, you can build more powerful, versatile, and insightful LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_22":{"__typename":"Paragraph","id":"09550dc2c048_22","name":"87b0","type":"H3","href":null,"layout":null,"metadata":null,"text":"LangChain","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_23":{"__typename":"Paragraph","id":"09550dc2c048_23","name":"2d81","type":"P","href":null,"layout":null,"metadata":null,"text":"In the ever-evolving landscape of artificial intelligence, large language models (LLMs) have emerged as a transformative force, capable of generating human-quality text, answering questions, and more. However, harnessing their full potential can be a complex endeavor. This is where LangChain steps in, offering a robust framework that simplifies the development and deployment of LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_24":{"__typename":"Paragraph","id":"09550dc2c048_24","name":"aeb3","type":"P","href":null,"layout":null,"metadata":null,"text":"While LLamaIndex focuses on bridging the gap between your data and LLMs, LangChain provides a different perspective. It offers a modular and extensible architecture that empowers developers to seamlessly combine LLMs with various data sources and services. This flexibility enables the creation of a wide range of applications that leverage the unique capabilities of LLMs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_25":{"__typename":"Paragraph","id":"09550dc2c048_25","name":"db75","type":"P","href":null,"layout":null,"metadata":null,"text":"At its core, LangChain consists of reusable components, including prompt templates, support for various LLMs such as OpenAI API, Bard, and Bloom, dynamic agents, and chains. These components can be artfully assembled to create complex LLM-powered applications, ranging from chatbots engaging in natural conversations to virtual assistants, content generation tools, and educational resources.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_26":{"__typename":"Paragraph","id":"09550dc2c048_26","name":"4ae0","type":"P","href":null,"layout":null,"metadata":null,"text":"LangChain is a versatile tool that, like LLamaIndex, unlocks the potential of LLMs but with a distinct focus on the application development process. Its modular and extensible architecture makes it easy for developers to create diverse LLM-powered applications. In the upcoming sections, we’ll delve deeper into LangChain’s features and explore the myriad possibilities it offers for LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_27":{"__typename":"Paragraph","id":"09550dc2c048_27","name":"1917","type":"H3","href":null,"layout":null,"metadata":null,"text":"Tools offered by Langchain:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_28":{"__typename":"Paragraph","id":"09550dc2c048_28","name":"6849","type":"H3","href":null,"layout":null,"metadata":null,"text":"Model I\u002FO:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*Qk7PU6HYRVomP0ZE":{"__typename":"ImageMetadata","id":"0*Qk7PU6HYRVomP0ZE","originalHeight":614,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fmodules\u002Fmodel_io\u002F"},"Paragraph:09550dc2c048_29":{"__typename":"Paragraph","id":"09550dc2c048_29","name":"dd23","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*Qk7PU6HYRVomP0ZE"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_30":{"__typename":"Paragraph","id":"09550dc2c048_30","name":"488f","type":"P","href":null,"layout":null,"metadata":null,"text":"When it comes to harnessing the potential of large language models (LLMs) through LangChain, the Module Model I\u002FO (Input\u002FOutput) stands as a pivotal core component. This feature offers a standardized and user-friendly method of interacting with LLMs, making it easier for developers to create LLM-powered applications that can tackle real-world challenges. The Module Model I\u002FO comprises three key elements:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_31":{"__typename":"Paragraph","id":"09550dc2c048_31","name":"46f6","type":"P","href":null,"layout":null,"metadata":null,"text":"Prompts: These are like instructions for LLMs, telling them what to do and how to do it. For instance, a prompt could guide an LLM to generate a poem, translate a sentence, or answer a question.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_32":{"__typename":"Paragraph","id":"09550dc2c048_32","name":"6030","type":"P","href":null,"layout":null,"metadata":null,"text":"Language Models: Think of these as the engines behind LangChain applications. They’re responsible for tasks such as text generation, language translation, and providing answers to queries. LangChain offers support for a wide array of LLMs, including popular ones like the OpenAI API, Bard, and Bloom.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_33":{"__typename":"Paragraph","id":"09550dc2c048_33","name":"e03b","type":"P","href":null,"layout":null,"metadata":null,"text":"Input Parsers: Input parsers work their magic by converting user input into a format that LLMs can understand. For example, they can take a natural language question and transform it into a structured query for database searches.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_34":{"__typename":"Paragraph","id":"09550dc2c048_34","name":"bafa","type":"P","href":null,"layout":null,"metadata":null,"text":"The Module Model I\u002FO provides numerous advantages for developers:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_35":{"__typename":"Paragraph","id":"09550dc2c048_35","name":"b48e","type":"P","href":null,"layout":null,"metadata":null,"text":"Standardization: By offering a standardized way to interact with LLMs, it simplifies the process of building and maintaining LLM-powered applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_36":{"__typename":"Paragraph","id":"09550dc2c048_36","name":"747b","type":"P","href":null,"layout":null,"metadata":null,"text":"Flexibility: This feature is incredibly versatile, accommodating a diverse range of LLMs and input formats. Developers have the freedom to choose the tools that best suit their specific needs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_37":{"__typename":"Paragraph","id":"09550dc2c048_37","name":"8c11","type":"P","href":null,"layout":null,"metadata":null,"text":"Extensibility: Developers can take customization to the next level. The Module Model I\u002FO is extensible, allowing the creation of unique prompts, language models, and input parsers, which is perfect for tailoring LLM-powered applications to meet the precise requirements of users.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_38":{"__typename":"Paragraph","id":"09550dc2c048_38","name":"dc2a","type":"H3","href":null,"layout":null,"metadata":null,"text":"Retrieval:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*64xqbKMkJDaRwuQY":{"__typename":"ImageMetadata","id":"0*64xqbKMkJDaRwuQY","originalHeight":553,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fmodules\u002Fdata_connection\u002F"},"Paragraph:09550dc2c048_39":{"__typename":"Paragraph","id":"09550dc2c048_39","name":"6925","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*64xqbKMkJDaRwuQY"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_40":{"__typename":"Paragraph","id":"09550dc2c048_40","name":"7de5","type":"P","href":null,"layout":null,"metadata":null,"text":"In this amazing world of Large Language Model (LLM) applications, there’s often a need for personalized data that goes beyond what these models were originally trained on. It’s like asking an artist to paint a picture with colors they’ve never seen before. This mystical feat is achieved through the mystical process of Retrieval Augmented Generation (RAG), where external data is summoned and handed over to the LLM during the creation phase.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_41":{"__typename":"Paragraph","id":"09550dc2c048_41","name":"6350","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, imagine LangChain as your mystical wand, offering all the enchanting building blocks for RAG applications. From the simplest spells to the most intricate incantations, LangChain has it all covered. In this chapter of our magical documentation, we’ll delve into the art of retrieval — the process of summoning the data. But be warned, though it may sound simple, this sorcery holds subtle complexities and a treasure trove of secrets, entailing the use of several mystical modules.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_42":{"__typename":"Paragraph","id":"09550dc2c048_42","name":"0104","type":"P","href":null,"layout":null,"metadata":null,"text":"Document Loaders: These serve as the gateways to a vast realm of knowledge within LangChain. With over a hundred document loaders at your disposal, as well as connections to other prominent knowledge hubs like AirByte and Unstructured, you gain access to a library teeming with diverse documents. Whether they’re written in the HTML scrolls of the internet’s ancient past, the enigmatic symbols of PDFs, or the cryptic code runes, you can fetch them from both hidden s3 treasure troves and publicly accessible websites.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_43":{"__typename":"Paragraph","id":"09550dc2c048_43","name":"7696","type":"P","href":null,"layout":null,"metadata":null,"text":"Document Transformers: These components are the architects of data refinement. Their primary function is to split or chunk large documents into smaller, more digestible sections. LangChain offers an array of algorithms tailored for this task, each fine-tuned to handle specific document types, whether it’s the intricate language of code or the mystical world of markdown.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_44":{"__typename":"Paragraph","id":"09550dc2c048_44","name":"e6f6","type":"P","href":null,"layout":null,"metadata":null,"text":"Text Embedding Models: In the art of data retrieval, creating text embeddings is essential. These embeddings capture the essence of a text’s meaning, facilitating the discovery of related content. LangChain seamlessly integrates with over 25 different embedding providers and methods, ranging from open-source to proprietary API, giving you the flexibility to choose the one that best aligns with your project. Moreover, LangChain offers a standardized interface for easy model switching.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_45":{"__typename":"Paragraph","id":"09550dc2c048_45","name":"0ffe","type":"P","href":null,"layout":null,"metadata":null,"text":"Vector Stores: With the advent of embeddings, the need for efficient storage and retrieval mechanisms has grown. LangChain offers connections to over 50 distinct vector stores, from open-source local options to cloud-hosted proprietary solutions. This flexibility enables you to select the one that best suits your requirements, with the assurance of a standardized interface for smooth transitions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_46":{"__typename":"Paragraph","id":"09550dc2c048_46","name":"d873","type":"P","href":null,"layout":null,"metadata":null,"text":"Retrievers: Your journey doesn’t end with storage; you need retrieval methods to access your data. LangChain provides support for various retrieval algorithms, from straightforward semantic searches to advanced techniques that enhance performance.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_47":{"__typename":"Paragraph","id":"09550dc2c048_47","name":"4471","type":"P","href":null,"layout":null,"metadata":null,"text":"Parent Document Retriever: Think of this as a feature that allows you to explore not just individual documents, but also the larger context they belong to. It enables the creation of multiple retrievable sections within a single document, allowing you to navigate through both the details and the broader narrative.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_48":{"__typename":"Paragraph","id":"09550dc2c048_48","name":"8938","type":"P","href":null,"layout":null,"metadata":null,"text":"Self-Query Retriever: User queries are often a blend of straightforward requests and underlying metadata. The Self Query Retriever helps you extract the semantic essence of a query from the additional metadata and logic woven into it.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_49":{"__typename":"Paragraph","id":"09550dc2c048_49","name":"b7f2","type":"P","href":null,"layout":null,"metadata":null,"text":"Ensemble Retriever: Just like musicians in an orchestra, the Ensemble Retriever brings together documents from various sources and retrieval algorithms, blending them into a harmonious medley to enrich your data exploration.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_50":{"__typename":"Paragraph","id":"09550dc2c048_50","name":"b28c","type":"H3","href":null,"layout":null,"metadata":null,"text":"Chains:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_51":{"__typename":"Paragraph","id":"09550dc2c048_51","name":"cbb3","type":"P","href":null,"layout":null,"metadata":null,"text":"While using a Large Language Model (LLM) in isolation can handle simple tasks, more intricate applications demand the art of chaining LLMs, whether it’s LLMs working together or collaborating with other essential components.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_52":{"__typename":"Paragraph","id":"09550dc2c048_52","name":"96bb","type":"P","href":null,"layout":null,"metadata":null,"text":"LangChain unveils two overarching frameworks for this enchanting process. The traditional method involves using the Chain interface, while the contemporary approach employs the LangChain Expression Language (LCEL). For those embarking on new applications, LCEL reigns supreme for chain composition. However, we treasure several invaluable pre-built Chains, and we continue to support them, ensuring that both frameworks coexist harmoniously. As we journey onward, we’ll discover that Chains can even become integral elements within LCEL, proving that the two are not mutually exclusive. So, let’s embark on this magical journey into the world of Chains in LangChain.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_53":{"__typename":"Paragraph","id":"09550dc2c048_53","name":"27f9","type":"P","href":null,"layout":null,"metadata":null,"text":"Async API: The LangChain Async API introduces the ability to run LangChain Chains asynchronously, a valuable feature for enhancing the performance of chains with multiple intricate steps, such as document retrieval, translation, and summarization. Imagine the power of seamlessly orchestrating these actions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_54":{"__typename":"Paragraph","id":"09550dc2c048_54","name":"602c","type":"P","href":null,"layout":null,"metadata":null,"text":"Different Call Methods: LangChain Chains are at your beck and call through a variety of methods. The simplest path involves directly invoking the Chain.run() method. For those seeking more flexibility, the LangChain AgentExecutor offers a comprehensive approach, allowing you to chain chains together and execute them in parallel. The LangChain SDK provides a high-level API for both constructing and executing chains, simplifying the complex orchestration of your magical workflows.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_55":{"__typename":"Paragraph","id":"09550dc2c048_55","name":"41d6","type":"P","href":null,"layout":null,"metadata":null,"text":"Custom Chain: Your creativity knows no bounds in LangChain. The creation of custom chains allows you to craft unique workflows tailored to your needs, perfect for those intricate tasks that go beyond the realm of built-in chains. It’s like wielding the wand of customization in the world of chains.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_56":{"__typename":"Paragraph","id":"09550dc2c048_56","name":"70d5","type":"P","href":null,"layout":null,"metadata":null,"text":"Adding Memory (State): Imagine granting LangChain Chains the ability to remember past actions and conversations. With memory (state) augmentation, chains can seamlessly store and retrieve information between steps. This proves invaluable for tasks like maintaining conversation flow or tracking the progress of a complex chain, making your chains smarter and more intuitive.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_57":{"__typename":"Paragraph","id":"09550dc2c048_57","name":"5780","type":"P","href":null,"layout":null,"metadata":null,"text":"Using OpenAI Functions: LangChain Chains have the magical ability to call upon OpenAI functions, pre-trained machine learning models with the power to perform a myriad of tasks, including text generation, translation, and question answering. Moreover, you can seamlessly integrate the results of OpenAI functions into other steps within the chain, creating a seamless flow of information and action.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_58":{"__typename":"Paragraph","id":"09550dc2c048_58","name":"8583","type":"H3","href":null,"layout":null,"metadata":null,"text":"Memory:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*JC7MvW06ViVKON7F":{"__typename":"ImageMetadata","id":"0*JC7MvW06ViVKON7F","originalHeight":818,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":"https:\u002F\u002Fpython.langchain.com\u002Fassets\u002Fimages\u002Fmemory_diagram-0627c68230aa438f9b5419064d63cbbc.png"},"Paragraph:09550dc2c048_59":{"__typename":"Paragraph","id":"09550dc2c048_59","name":"f4ed","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*JC7MvW06ViVKON7F"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_60":{"__typename":"Paragraph","id":"09550dc2c048_60","name":"d659","type":"P","href":null,"layout":null,"metadata":null,"text":"In the mystical realm of Large Language Models (LLMs), conversational applications reign supreme. Within the tapestry of these conversations, a crucial element is the ability to reference information from earlier parts of the exchange. This ability to store and recall past interactions is aptly named “memory.” LangChain, the magical framework, offers an array of tools and utilities to infuse your systems with the gift of memory. Whether your needs are straightforward or intricate, LangChain’s memory system can be seamlessly integrated into chains, offering a dynamic blend of reading and writing actions. The knowledge within memory serves as a guiding light for LangChain Chains, ensuring they draw upon past interactions to enhance their responses.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_61":{"__typename":"Paragraph","id":"09550dc2c048_61","name":"7b1d","type":"P","href":null,"layout":null,"metadata":null,"text":"Memory systems are shaped by two core design decisions: how state is stored and how it is queried. Underneath the mystical veil of memory lies a historical record of chat messages, meticulously preserved in various forms, from in-memory lists to resilient databases. The act of querying this knowledge reveals a rich tapestry, and the memory module boasts a repertoire of data structures and algorithms that provide unique perspectives on this trove of wisdom.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_62":{"__typename":"Paragraph","id":"09550dc2c048_62","name":"e684","type":"P","href":null,"layout":null,"metadata":null,"text":"With LangChain, the possibilities for memory are endless. You can build a simple memory system that retrieves the most recent messages or opt for a more complex setup that extracts entities from stored messages and provides information relevant to the current conversation. Each application has its unique memory requirements, and the memory module offers both simplicity for beginners and the flexibility to craft custom systems when the need arises.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_63":{"__typename":"Paragraph","id":"09550dc2c048_63","name":"26de","type":"P","href":null,"layout":null,"metadata":null,"text":"In this enchanted journey into LangChain Memory, we’ll uncover the art of storing and querying memories, understanding the variables they return, and the different ways memory can be harnessed within chains. So, let’s embark on this magical expedition to reveal the true essence of memory in LangChain.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_64":{"__typename":"Paragraph","id":"09550dc2c048_64","name":"372f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Agents:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_65":{"__typename":"Paragraph","id":"09550dc2c048_65","name":"a5a7","type":"P","href":null,"layout":null,"metadata":null,"text":"In the enchanting world of LangChain, Agents emerge as powerful entities, wielding the magical essence of Large Language Models (LLMs) to orchestrate sequences of actions. Unlike conventional chains, where actions are preordained in code, Agents harness the reasoning capabilities of a language model to dynamically determine the next steps and their order. Within this mystical realm, some crucial terminologies and schemas await your exploration:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_66":{"__typename":"Paragraph","id":"09550dc2c048_66","name":"3907","type":"P","href":null,"layout":null,"metadata":null,"text":"Agent Action: These are like incantations that guide an agent’s actions. Each AgentAction consists of a tool property (the tool to be invoked) and a tool_input property (the input for that tool).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_67":{"__typename":"Paragraph","id":"09550dc2c048_67","name":"0641","type":"P","href":null,"layout":null,"metadata":null,"text":"Agent Finish: This signifies the end of an agent’s task, marked by a return_values parameter, typically containing an output (usually a string) that is to be returned.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_68":{"__typename":"Paragraph","id":"09550dc2c048_68","name":"3bcb","type":"P","href":null,"layout":null,"metadata":null,"text":"Intermediate Steps: These represent past agent actions and their corresponding outcomes, allowing the agent to keep track of its progress. These steps are like chapters in the agent’s book of spells and are essential for guiding future iterations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_69":{"__typename":"Paragraph","id":"09550dc2c048_69","name":"c8a8","type":"P","href":null,"layout":null,"metadata":null,"text":"Agents, the orchestrators of magic, are chains imbued with the power to decide the next course of action. They are fueled by a language model and a prompt, receiving inputs such as the list of available tools, user queries, and the history of previous actions. In return, agents conjure up either the next action to take (AgentAction) or the final response to be conveyed to the user (AgentFinish).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_70":{"__typename":"Paragraph","id":"09550dc2c048_70","name":"2145","type":"P","href":null,"layout":null,"metadata":null,"text":"At the heart of an agent’s power are its tools — functions that the agent calls upon. Yet, the key to the agent’s success lies in providing access to the right tools and crafting their descriptions to align perfectly with the agent’s needs. LangChain, like a treasure chest of magical artifacts, offers a wide range of tools to begin your journey and also empowers you to define custom tools with personalized descriptions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_71":{"__typename":"Paragraph","id":"09550dc2c048_71","name":"c7f4","type":"P","href":null,"layout":null,"metadata":null,"text":"Toolkits, akin to a magician’s collection of spell books, encompass groups of tools needed to achieve specific objectives. These toolkits, often composed of 3–5 essential tools, hold the key to an agent’s versatility, allowing them to take on various quests.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_72":{"__typename":"Paragraph","id":"09550dc2c048_72","name":"23be","type":"P","href":null,"layout":null,"metadata":null,"text":"The AgentExecutor serves as the runtime for agents, enacting the agent’s decisions and executing their actions. This runtime handles complexities such as non-existent tools, tool errors, and unparseable agent output, ensuring a smooth magical performance. There are other experimental runtimes supported as well, each carrying its unique flavor of enchantment.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_73":{"__typename":"Paragraph","id":"09550dc2c048_73","name":"6bba","type":"P","href":null,"layout":null,"metadata":null,"text":"In this magical journey of unraveling LangChain Agents, we will delve into building an agent from scratch using LangChain Expression Language, crafting custom tools, and running the agent within a custom loop. We will also uncover the power of memory in enabling seamless conversations with the agent, adding depth and context to your interactions. So, prepare to embark on this enchanting expedition into the realm of LangChain Agents.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_74":{"__typename":"Paragraph","id":"09550dc2c048_74","name":"e69d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Key Applications","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_75":{"__typename":"Paragraph","id":"09550dc2c048_75","name":"10f4","type":"H3","href":null,"layout":null,"metadata":null,"text":"LangChain:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_76":{"__typename":"Paragraph","id":"09550dc2c048_76","name":"10f6","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Text generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_77":{"__typename":"Paragraph","id":"09550dc2c048_77","name":"c1e3","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Translation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_78":{"__typename":"Paragraph","id":"09550dc2c048_78","name":"8e00","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Question answering","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_79":{"__typename":"Paragraph","id":"09550dc2c048_79","name":"76dd","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Summarization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_80":{"__typename":"Paragraph","id":"09550dc2c048_80","name":"afb5","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Classification","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_81":{"__typename":"Paragraph","id":"09550dc2c048_81","name":"a2df","type":"H3","href":null,"layout":null,"metadata":null,"text":"LlamaIndex:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_82":{"__typename":"Paragraph","id":"09550dc2c048_82","name":"a4a2","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Document search and retrieval","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_83":{"__typename":"Paragraph","id":"09550dc2c048_83","name":"46b5","type":"BQ","href":null,"layout":null,"metadata":null,"text":"LLM augmentation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_84":{"__typename":"Paragraph","id":"09550dc2c048_84","name":"151a","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Chatbots and virtual assistants","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_85":{"__typename":"Paragraph","id":"09550dc2c048_85","name":"e7e0","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Data analytics","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_86":{"__typename":"Paragraph","id":"09550dc2c048_86","name":"4d15","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Content generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_87":{"__typename":"Paragraph","id":"09550dc2c048_87","name":"9cb6","type":"H3","href":null,"layout":null,"metadata":null,"text":"Summary","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_88":{"__typename":"Paragraph","id":"09550dc2c048_88","name":"2159","type":"P","href":null,"layout":null,"metadata":null,"text":"In the world of data and language tools, we have two strong contenders: LlamaIndex and LangChain. LlamaIndex boasts impressive speed and accuracy, making it excellent for tasks like document search and enhancing large language models. It’s like a superhero for handling customer support, code generation, and chatbots efficiently. On the other hand, LangChain offers flexibility and versatility, serving as a multi-talented tool with an extensible nature. It’s easier to use with a simple interface and abundant documentation. Additionally, LangChain is compatible with a broader range of language models. You can leverage LangChain for creating chatbots with various capabilities, including poetry generation, language translation, and code creation across multiple programming languages. In this comparison, LlamaIndex excels in data indexing and language model enhancement, while LangChain stands out for its versatility and adaptability in building robust applications with large language models.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_89":{"__typename":"Paragraph","id":"09550dc2c048_89","name":"c141","type":"H4","href":null,"layout":null,"metadata":null,"text":"References:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_90":{"__typename":"Paragraph","id":"09550dc2c048_90","name":"befd","type":"P","href":null,"layout":null,"metadata":null,"text":"Langchain Documentation","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":23,"href":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fget_started\u002Fintroduction","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:09550dc2c048_91":{"__typename":"Paragraph","id":"09550dc2c048_91","name":"9f00","type":"P","href":null,"layout":null,"metadata":null,"text":"LLamaIndex Documentation","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":24,"href":"https:\u002F\u002Fdocs.llamaindex.ai\u002Fen\u002Fv0.8.36\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Tag:langchain":{"__typename":"Tag","id":"langchain","displayTitle":"Langchain","normalizedTagSlug":"langchain"},"Tag:llamaindex":{"__typename":"Tag","id":"llamaindex","displayTitle":"Llamaindex","normalizedTagSlug":"llamaindex"},"Tag:llm":{"__typename":"Tag","id":"llm","displayTitle":"Llm","normalizedTagSlug":"llm"},"Tag:artificial-intelligence":{"__typename":"Tag","id":"artificial-intelligence","displayTitle":"Artificial Intelligence","normalizedTagSlug":"artificial-intelligence"},"Tag:technology":{"__typename":"Tag","id":"technology","displayTitle":"Technology","normalizedTagSlug":"technology"},"Post:4900989752ac":{"__typename":"Post","id":"4900989752ac","collection":null,"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"1f26","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"2e89","startIndex":27,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"f6ce","startIndex":74,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"7326","startIndex":87,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:09550dc2c048_0"},{"__ref":"Paragraph:09550dc2c048_1"},{"__ref":"Paragraph:09550dc2c048_2"},{"__ref":"Paragraph:09550dc2c048_3"},{"__ref":"Paragraph:09550dc2c048_4"},{"__ref":"Paragraph:09550dc2c048_5"},{"__ref":"Paragraph:09550dc2c048_6"},{"__ref":"Paragraph:09550dc2c048_7"},{"__ref":"Paragraph:09550dc2c048_8"},{"__ref":"Paragraph:09550dc2c048_9"},{"__ref":"Paragraph:09550dc2c048_10"},{"__ref":"Paragraph:09550dc2c048_11"},{"__ref":"Paragraph:09550dc2c048_12"},{"__ref":"Paragraph:09550dc2c048_13"},{"__ref":"Paragraph:09550dc2c048_14"},{"__ref":"Paragraph:09550dc2c048_15"},{"__ref":"Paragraph:09550dc2c048_16"},{"__ref":"Paragraph:09550dc2c048_17"},{"__ref":"Paragraph:09550dc2c048_18"},{"__ref":"Paragraph:09550dc2c048_19"},{"__ref":"Paragraph:09550dc2c048_20"},{"__ref":"Paragraph:09550dc2c048_21"},{"__ref":"Paragraph:09550dc2c048_22"},{"__ref":"Paragraph:09550dc2c048_23"},{"__ref":"Paragraph:09550dc2c048_24"},{"__ref":"Paragraph:09550dc2c048_25"},{"__ref":"Paragraph:09550dc2c048_26"},{"__ref":"Paragraph:09550dc2c048_27"},{"__ref":"Paragraph:09550dc2c048_28"},{"__ref":"Paragraph:09550dc2c048_29"},{"__ref":"Paragraph:09550dc2c048_30"},{"__ref":"Paragraph:09550dc2c048_31"},{"__ref":"Paragraph:09550dc2c048_32"},{"__ref":"Paragraph:09550dc2c048_33"},{"__ref":"Paragraph:09550dc2c048_34"},{"__ref":"Paragraph:09550dc2c048_35"},{"__ref":"Paragraph:09550dc2c048_36"},{"__ref":"Paragraph:09550dc2c048_37"},{"__ref":"Paragraph:09550dc2c048_38"},{"__ref":"Paragraph:09550dc2c048_39"},{"__ref":"Paragraph:09550dc2c048_40"},{"__ref":"Paragraph:09550dc2c048_41"},{"__ref":"Paragraph:09550dc2c048_42"},{"__ref":"Paragraph:09550dc2c048_43"},{"__ref":"Paragraph:09550dc2c048_44"},{"__ref":"Paragraph:09550dc2c048_45"},{"__ref":"Paragraph:09550dc2c048_46"},{"__ref":"Paragraph:09550dc2c048_47"},{"__ref":"Paragraph:09550dc2c048_48"},{"__ref":"Paragraph:09550dc2c048_49"},{"__ref":"Paragraph:09550dc2c048_50"},{"__ref":"Paragraph:09550dc2c048_51"},{"__ref":"Paragraph:09550dc2c048_52"},{"__ref":"Paragraph:09550dc2c048_53"},{"__ref":"Paragraph:09550dc2c048_54"},{"__ref":"Paragraph:09550dc2c048_55"},{"__ref":"Paragraph:09550dc2c048_56"},{"__ref":"Paragraph:09550dc2c048_57"},{"__ref":"Paragraph:09550dc2c048_58"},{"__ref":"Paragraph:09550dc2c048_59"},{"__ref":"Paragraph:09550dc2c048_60"},{"__ref":"Paragraph:09550dc2c048_61"},{"__ref":"Paragraph:09550dc2c048_62"},{"__ref":"Paragraph:09550dc2c048_63"},{"__ref":"Paragraph:09550dc2c048_64"},{"__ref":"Paragraph:09550dc2c048_65"},{"__ref":"Paragraph:09550dc2c048_66"},{"__ref":"Paragraph:09550dc2c048_67"},{"__ref":"Paragraph:09550dc2c048_68"},{"__ref":"Paragraph:09550dc2c048_69"},{"__ref":"Paragraph:09550dc2c048_70"},{"__ref":"Paragraph:09550dc2c048_71"},{"__ref":"Paragraph:09550dc2c048_72"},{"__ref":"Paragraph:09550dc2c048_73"},{"__ref":"Paragraph:09550dc2c048_74"},{"__ref":"Paragraph:09550dc2c048_75"},{"__ref":"Paragraph:09550dc2c048_76"},{"__ref":"Paragraph:09550dc2c048_77"},{"__ref":"Paragraph:09550dc2c048_78"},{"__ref":"Paragraph:09550dc2c048_79"},{"__ref":"Paragraph:09550dc2c048_80"},{"__ref":"Paragraph:09550dc2c048_81"},{"__ref":"Paragraph:09550dc2c048_82"},{"__ref":"Paragraph:09550dc2c048_83"},{"__ref":"Paragraph:09550dc2c048_84"},{"__ref":"Paragraph:09550dc2c048_85"},{"__ref":"Paragraph:09550dc2c048_86"},{"__ref":"Paragraph:09550dc2c048_87"},{"__ref":"Paragraph:09550dc2c048_88"},{"__ref":"Paragraph:09550dc2c048_89"},{"__ref":"Paragraph:09550dc2c048_90"},{"__ref":"Paragraph:09550dc2c048_91"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:8ecd3d43dbb4"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@zahidali133\u002Fcomparison-of-llamaindex-and-langchain-4900989752ac","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"data-science"},{"__typename":"Topic","slug":"programming"}],"isPublished":true,"latestPublishedVersion":"09550dc2c048","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":1},"createdAt":1698663352510,"firstPublishedAt":1698664252236,"latestPublishedAt":1698673079299,"clapCount":29,"allowResponses":true,"isLimitedState":false,"title":"Comparison of LLamaIndex and LangChain","isSeries":false,"sequence":null,"uniqueSlug":"comparison-of-llamaindex-and-langchain-4900989752ac","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":13.387735849056604,"previewContent":{"__typename":"PreviewContent","subtitle":"In the world of data and language tools, we have two strong contenders: LlamaIndex and LangChain. LlamaIndex boasts impressive speed and…"},"previewImage":{"__ref":"ImageMetadata:0*Qk7PU6HYRVomP0ZE"},"isShortform":false,"seoTitle":"","updatedAt":1698673084165,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:langchain"},{"__ref":"Tag:llamaindex"},{"__ref":"Tag:llm"},{"__ref":"Tag:artificial-intelligence"},{"__ref":"Tag:technology"}],"pendingCollection":null,"statusForCollection":null,"detectedLanguage":"en","wordCount":3402,"layerCake":0}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT","inDisabledExperiment":false}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.d12908bb.js"></script><script src="https://cdn-client.medium.com/lite/static/js/3057.5e22bbb0.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.4f8f08ab.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.d6d5fe73.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.2021fe63.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/120.a1050cd4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1752.0a0e21e3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6733.1d85727b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4711.043615ac.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8695.09acff9e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4341.09a484a0.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3154.23d7fa54.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5203.e7a22052.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1957.fe63a49e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9599.af0299d5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1711.02ed88a9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5268.5f96ae45.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9114.49b6b911.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5459.80a6ee18.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6804.4b5be6c2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9174.7b097d16.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4129.ee8ae2c8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8580.feeb2549.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1802.694a29bf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2295.fc4d4022.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4078.da7800a7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8883.c8b03d13.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2550.1e47c72a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9408.a4724b16.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/397.2e086ee7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9150.42fafb2e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5005.b5d4a37c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2393.2acb9140.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5404.d8739341.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.bbd8a9a7.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v84a3a4012de94ce1a686ba8c167c359c1696973893317" integrity="sha512-euoFGowhlaLqXsPWQ48qSkBSCFs3DPRyiwVu3FjR96cMPx+Fr+gpWRhIafcHwqwCqWS42RZhIudOvEI+Ckf6MA==" data-cf-beacon='{"rayId":"8320c913bdb33b93","b":1,"version":"2023.10.0","token":"0b5f665943484354a59c39c6833f7078"}' crossorigin="anonymous"></script>
</body></html>